{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from skimage.feature import local_binary_pattern, hog, graycomatrix, graycoprops\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isskin(image):\n",
    "    h_min = 0\n",
    "    h_max = 128\n",
    "    s_min = 100\n",
    "    s_max = 150\n",
    "    v_min = 0\n",
    "    v_max = 128\n",
    "\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    lower_hsv = np.array([h_min, s_min, v_min])\n",
    "    upper_hsv = np.array([h_max, s_max, v_max])\n",
    "\n",
    "    skinMask = cv2.inRange(hsv_image, lower_hsv, upper_hsv)\n",
    "\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    skinMask = cv2.erode(skinMask, kernel, iterations=2)\n",
    "    skinMask = cv2.dilate(skinMask, kernel, iterations=2)\n",
    "\n",
    "    skinMask = cv2.GaussianBlur(skinMask, (5, 5), 0)\n",
    "\n",
    "    skin = cv2.bitwise_and(image, image, mask=skinMask)\n",
    "\n",
    "    # alpha = np.uint8(skinMask > 0) * 255\n",
    "    # result = cv2.merge((skin, alpha))\n",
    "\n",
    "    return skin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_gamma_correction(image, gamma=1.0):\n",
    "    inv_gamma = 1.0 / gamma\n",
    "    table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in range(256)]).astype(\"uint8\")\n",
    "    return cv2.LUT(image, table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skin Segmentation\n",
    "def extract_skin_and_preprocess(img):\n",
    "    skin_img = isskin(img)\n",
    "\n",
    "    if skin_img.shape[2] == 4:\n",
    "        skin_img = skin_img[:, :, :3]\n",
    "        \n",
    "    # corrected = apply_gamma_correction(skin_img)\n",
    "    # denoised = cv2.fastNlMeansDenoising(corrected, h=10)\n",
    "    denoised = cv2.fastNlMeansDenoising(skin_img, h=10)\n",
    "    img_resized = cv2.resize(denoised, (128, 128))\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img_resized, cv2.COLOR_BGR2GRAY)\n",
    "    return gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset_path):\n",
    "    classes = {'Acne': 0, 'Bags': 1, 'Redness': 2}\n",
    "    X, y = [], []\n",
    "\n",
    "    for class_name, label in classes.items():\n",
    "        class_path = os.path.join(dataset_path, class_name)\n",
    "        if not os.path.exists(class_path):\n",
    "            print(f\"Folder not found: {class_path}\")\n",
    "            continue\n",
    "        for subfolder in os.listdir(class_path):\n",
    "            subfolder_path = os.path.join(class_path, subfolder)\n",
    "            if os.path.isdir(subfolder_path):\n",
    "                for img_name in os.listdir(subfolder_path):\n",
    "                    img_path = os.path.join(subfolder_path, img_name)\n",
    "                    img = cv2.imread(img_path)\n",
    "                    if img is not None:\n",
    "                        img = extract_skin_and_preprocess(img)\n",
    "                        X.append(img)\n",
    "                        y.append(label)\n",
    "                    else:\n",
    "                        print(f\"Failed to load image: {img_path}\")\n",
    "\n",
    "    print(f\"Loaded {len(X)} images from {len(classes)} classes.\")\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 471 images from 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "dataset_path = 'Dataset'\n",
    "X, y = load_data(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LBP Feature Extraction\n",
    "def extract_lbp_features(img, P=8, R=1):\n",
    "    # gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    lbp = local_binary_pattern(img, P=P, R=R, method='uniform')\n",
    "    hist, _ = np.histogram(lbp, bins=np.arange(0, P+3), range=(0, P+2))\n",
    "    hist = hist.astype('float')\n",
    "    hist /= (hist.sum() + 1e-6)\n",
    "    return hist\n",
    "\n",
    "# HOG Feature Extraction\n",
    "def extract_hog_features(img, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2)):\n",
    "    # gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    features, _ = hog(img, orientations=orientations, pixels_per_cell=pixels_per_cell, cells_per_block=cells_per_block, block_norm='L2-Hys', visualize=True)\n",
    "    return features\n",
    "\n",
    "# Color Histogram Feature Extraction\n",
    "def extract_color_features(img, h_range=(0, 128), s_range=(100, 150), v_range=(0, 128)):\n",
    "    # bgr = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    hist_h = cv2.calcHist([hsv], [0], None, [256], h_range)\n",
    "    hist_s = cv2.calcHist([hsv], [1], None, [256], s_range)\n",
    "    hist_v = cv2.calcHist([hsv], [2], None, [256], v_range)\n",
    "    hist_h /= hist_h.sum() + 1e-6\n",
    "    hist_s /= hist_s.sum() + 1e-6\n",
    "    hist_v /= hist_v.sum() + 1e-6\n",
    "    return np.concatenate([hist_h.flatten(), hist_s.flatten(), hist_v.flatten()])\n",
    "\n",
    "# GLCM Feature Extraction\n",
    "def extract_glcm_features(img, distances=[5], angles=[0], properties=('contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation')):\n",
    "    # gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    glcm = graycomatrix(img, distances=distances, angles=angles, levels=256, symmetric=True, normed=True)\n",
    "    glcm_features = []\n",
    "    for prop in properties:\n",
    "        glcm_features.append(graycoprops(glcm, prop).flatten())\n",
    "    return np.concatenate(glcm_features)\n",
    "\n",
    "# Combined Feature Extraction\n",
    "def extract_combined_features(img, h_range=(0, 128), s_range=(100, 150), v_range=(0, 128)):\n",
    "    lbp_features = extract_lbp_features(img)\n",
    "    hog_features = extract_hog_features(img)\n",
    "    color_features = extract_color_features(cv2.cvtColor(img, cv2.COLOR_GRAY2BGR), \n",
    "                                            h_range, s_range, v_range)\n",
    "    glcm_features = extract_glcm_features(img)\n",
    "    return np.concatenate([lbp_features, hog_features, color_features, glcm_features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features = np.array([extract_combined_features(img, h_range=(0, 128), s_range=(100, 150), v_range=(0, 128)) for img in X])\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_features, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hansel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:31:05] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\Hansel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:32:26] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\Hansel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:32:45] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\Hansel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:33:04] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\Hansel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:33:23] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\Hansel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:33:42] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\Hansel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:34:18] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\Hansel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:35:41] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\Hansel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:36:00] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\Hansel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:36:18] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\Hansel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:36:37] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\Hansel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:36:56] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\Hansel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:37:32] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\Hansel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:38:53] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\Hansel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:39:12] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\Hansel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:39:31] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\Hansel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:39:49] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\Hansel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:40:07] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Train base models\n",
    "base_models = [\n",
    "    ('svm', SVC(kernel='linear', probability=True)),\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('xgb', XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42))\n",
    "]\n",
    "# Meta-model\n",
    "meta_model_lr = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "meta_model_svm = SVC(kernel='linear', probability=True)\n",
    "meta_model_rf = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "\n",
    "# Stacking Classifier\n",
    "stacking_lr = StackingClassifier(estimators=base_models, final_estimator=meta_model_lr, cv=5)\n",
    "stacking_svm = StackingClassifier(estimators=base_models, final_estimator=meta_model_svm, cv=5)\n",
    "stacking_rf = StackingClassifier(estimators=base_models, final_estimator=meta_model_rf, cv=5)\n",
    "stacking_lr.fit(X_train, y_train)\n",
    "stacking_svm.fit(X_train, y_train)\n",
    "stacking_rf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model\n",
    "y_pred_lr = stacking_lr.predict(X_val)\n",
    "y_pred_svm = stacking_svm.predict(X_val)\n",
    "y_pred_rf = stacking_rf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy Stacking With Logistic Regression With Gamma Correction:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.16      0.23        31\n",
      "           1       0.53      0.79      0.63        33\n",
      "           2       0.61      0.65      0.62        31\n",
      "\n",
      "    accuracy                           0.54        95\n",
      "   macro avg       0.51      0.53      0.50        95\n",
      "weighted avg       0.51      0.54      0.50        95\n",
      "\n",
      "Validation Accuracy Stacking With Support Vector Machine With Gamma Correction:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.13      0.18        31\n",
      "           1       0.53      0.76      0.62        33\n",
      "           2       0.57      0.65      0.61        31\n",
      "\n",
      "    accuracy                           0.52        95\n",
      "   macro avg       0.47      0.51      0.47        95\n",
      "weighted avg       0.47      0.52      0.47        95\n",
      "\n",
      "Validation Accuracy Stacking With Random Forest With Gamma Correction:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.19      0.24        31\n",
      "           1       0.51      0.70      0.59        33\n",
      "           2       0.53      0.52      0.52        31\n",
      "\n",
      "    accuracy                           0.47        95\n",
      "   macro avg       0.45      0.47      0.45        95\n",
      "weighted avg       0.45      0.47      0.45        95\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Validation Accuracy Stacking With Logistic Regression With Gamma Correction:\")\n",
    "print(classification_report(y_val, y_pred_lr))\n",
    "print(f\"Validation Accuracy Stacking With Support Vector Machine With Gamma Correction:\")\n",
    "print(classification_report(y_val, y_pred_svm))\n",
    "print(f\"Validation Accuracy Stacking With Random Forest With Gamma Correction:\")\n",
    "print(classification_report(y_val, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m     18\u001b[0m ranges \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m128\u001b[39m), (\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m256\u001b[39m), (\u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m200\u001b[39m), (\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m255\u001b[39m), (\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m150\u001b[39m), (\u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m150\u001b[39m), (\u001b[38;5;241m80\u001b[39m, \u001b[38;5;241m175\u001b[39m), (\u001b[38;5;241m80\u001b[39m, \u001b[38;5;241m200\u001b[39m)]\n\u001b[1;32m---> 19\u001b[0m best_ranges, best_accuracy \u001b[38;5;241m=\u001b[39m find_best_hsv_ranges(\u001b[43mX\u001b[49m, y, ranges)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Ranges:\u001b[39m\u001b[38;5;124m\"\u001b[39m, best_ranges, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Accuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, best_accuracy)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "def find_best_hsv_ranges(X, y, ranges):\n",
    "    best_accuracy = 0\n",
    "    best_ranges = None\n",
    "    for h_range, s_range, v_range in itertools.product(ranges, ranges, ranges):\n",
    "        print(f\"Testing ranges H={h_range}, S={s_range}, V={v_range}\")\n",
    "        X_features = np.array([extract_combined_features(img, h_range, s_range, v_range) for img in X])\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_features, y, test_size=0.2, random_state=42)\n",
    "        pickle.load(open(\"kent.pkl\", \"rb\"))\n",
    "        y_pred = model.predict(X_val)\n",
    "        accuracy = accuracy_score(y_val, y_pred)\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_ranges = (h_range, s_range, v_range)\n",
    "            print(f\"New best accuracy: {accuracy} with ranges H={h_range}, S={s_range}, V={v_range}\")\n",
    "    return best_ranges, best_accuracy\n",
    "\n",
    "# Example usage\n",
    "ranges = [(0, 128), (128, 256), (50, 200), (100, 255), (100, 150), (50, 150), (80, 175), (80, 200)]\n",
    "best_ranges, best_accuracy = find_best_hsv_ranges(X, y, ranges)\n",
    "print(\"Best Ranges:\", best_ranges, \"Best Accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_hsv_ranges(X, y, ranges):\n",
    "    best_accuracy = 0\n",
    "    best_ranges = None\n",
    "    for h_range, s_range, v_range in itertools.product(ranges, ranges, ranges):\n",
    "        print(f\"Testing ranges H={h_range}, S={s_range}, V={v_range}\")\n",
    "        X_features = np.array([extract_combined_features(img, h_range, s_range, v_range) for img in X])\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_features, y, test_size=0.2, random_state=42)\n",
    "        pickle.load(open(\"kent.pkl\", \"rb\"))\n",
    "        y_pred = model.predict(X_val)\n",
    "        accuracy = accuracy_score(y_val, y_pred)\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_ranges = (h_range, s_range, v_range)\n",
    "            print(f\"New best accuracy: {accuracy} with ranges H={h_range}, S={s_range}, V={v_range}\")\n",
    "    return best_ranges, best_accuracy\n",
    "\n",
    "# Example usage\n",
    "ranges = [(0, 128), (128, 256), (100, 150), (80, 175)]\n",
    "best_ranges, best_accuracy = find_best_hsv_ranges(X, y, ranges)\n",
    "print(\"Best Ranges:\", best_ranges, \"Best Accuracy:\", best_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
