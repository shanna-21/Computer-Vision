{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset_path):\n",
    "    classes = {'Acne': 0, 'Bags': 1, 'Redness': 2}  # Map class names to labels\n",
    "    X, y = [], []\n",
    "    for class_name, label in classes.items():\n",
    "        class_path = os.path.join(dataset_path, class_name)\n",
    "        if not os.path.exists(class_path):\n",
    "            print(f\"Folder not found: {class_path}\")\n",
    "            continue\n",
    "        for subfolder in os.listdir(class_path):  # Iterate through subfolders (0-10)\n",
    "            subfolder_path = os.path.join(class_path, subfolder)\n",
    "            if os.path.isdir(subfolder_path):\n",
    "                for img_name in os.listdir(subfolder_path):  # Iterate through images\n",
    "                    img_path = os.path.join(subfolder_path, img_name)\n",
    "                    img = cv2.imread(img_path)\n",
    "                    if img is not None:\n",
    "                        img = cv2.resize(img, (128, 128))  # Resize images to 128x128\n",
    "                        X.append(img)\n",
    "                        y.append(label)\n",
    "                    else:\n",
    "                        print(f\"Failed to load image: {img_path}\")\n",
    "    print(f\"Loaded {len(X)} images from {len(classes)} classes.\")\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance_image(img):\n",
    "    # Convert to grayscale and apply histogram equalization\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    equalized = cv2.equalizeHist(gray)\n",
    "    \n",
    "    # Denoise the image\n",
    "    denoised = cv2.fastNlMeansDenoising(equalized, h=10)\n",
    "    \n",
    "    # Convert back to a 3-channel image\n",
    "    enhanced = cv2.cvtColor(denoised, cv2.COLOR_GRAY2BGR)\n",
    "    return enhanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_skin(img):\n",
    "    # Convert to HSV color space\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Define skin color range\n",
    "    lower_skin = np.array([0, 48, 80], dtype=np.uint8)\n",
    "    upper_skin = np.array([20, 255, 255], dtype=np.uint8)\n",
    "    \n",
    "    # Create a mask for skin region\n",
    "    mask = cv2.inRange(hsv, lower_skin, upper_skin)\n",
    "    \n",
    "    # Apply the mask to the image\n",
    "    segmented = cv2.bitwise_and(img, img, mask=mask)\n",
    "    return segmented\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import local_binary_pattern, hog\n",
    "\n",
    "def extract_features(img):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    features, hog_image = hog(gray, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=True)\n",
    "    # Normalize HOG features (if needed)\n",
    "    features = features.astype('float')\n",
    "    features /= (features.sum() + 1e-6)  # Normalize\n",
    "\n",
    "    # # Extract LBP features\n",
    "    # lbp = local_binary_pattern(gray, P=8, R=1, method='uniform')\n",
    "    \n",
    "    # Flatten and normalize LBP histogram\n",
    "    # hist, _ = np.histogram(lbp, bins=np.arange(0, 10), range=(0, 9))\n",
    "    # hist = hist.astype('float')\n",
    "    # hist /= (hist.sum() + 1e-6)  # Normalize\n",
    "    \n",
    "    # return hist\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 470 images from 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "X, y = load_data('Dataset')\n",
    "\n",
    "# Normalize images\n",
    "X = X / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Enhance images\n",
    "# X_enhanced = np.array([enhance_image((img * 255).astype(np.uint8)) for img in X])\n",
    "\n",
    "# # Segment skin regions\n",
    "# X_segmented = np.array([segment_skin(img) for img in X_enhanced])\n",
    "\n",
    "# # Extract features for traditional models\n",
    "# X_features = np.array([extract_features(img) for img in X_segmented])\n",
    "\n",
    "# Split data into train and test sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_features, y, test_size=0.2, random_state=42)\n",
    "X_flat = X.reshape(X.shape[0], -1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.68      0.67        31\n",
      "           1       0.83      0.73      0.77        33\n",
      "           2       0.64      0.70      0.67        30\n",
      "\n",
      "    accuracy                           0.70        94\n",
      "   macro avg       0.71      0.70      0.70        94\n",
      "weighted avg       0.71      0.70      0.70        94\n",
      "\n",
      "SVM Accuracy: 0.7021276595744681\n"
     ]
    }
   ],
   "source": [
    "# Train SVM model\n",
    "svm_model = SVC(kernel='linear', probability=True)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate SVM\n",
    "svm_predictions = svm_model.predict(X_test)\n",
    "print(\"SVM Classification Report:\\n\", classification_report(y_test, svm_predictions))\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_test, svm_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: Redness\n"
     ]
    }
   ],
   "source": [
    "def predict_image(input_image_path, model, image_size=(128, 128)):\n",
    "    # Read the input image\n",
    "    img = cv2.imread(input_image_path)\n",
    "\n",
    "    # Convert the image to grayscale (if required)\n",
    "    # gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Resize the image to the same size as the training images\n",
    "    resized = cv2.resize(img, image_size)\n",
    "\n",
    "    # Flatten the image to match the input format for SVC (2D array)\n",
    "    input_vector = resized.flatten().reshape(1, -1)\n",
    "\n",
    "    # Predict the class of the input image\n",
    "    prediction = model.predict(input_vector)\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "input_image_path = './Input/red girl 3.png'\n",
    "prediction = predict_image(input_image_path, svm_model, image_size=(128,128))\n",
    "if prediction == 0:\n",
    "    print(f'Predicted class: Acne')\n",
    "elif prediction == 1:\n",
    "    print(f'Predicted class: Eyebags')\n",
    "elif prediction == 2:\n",
    "    print(f'Predicted class: Redness')\n",
    "    \n",
    "# print(svm_model.predict('./Input/black ppl.jpg'))\n",
    "# print(svm_model.predict('./Input/eyebags.jpg'))\n",
    "# print(svm_model.predict('./Input/red girl.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hansel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInvalid input shape for input Tensor(\"data:0\", shape=(None, 9), dtype=float32). Expected shape (None, 128, 128, 3), but input has incompatible shape (None, 9)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 9), dtype=float32)\n  • training=True\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m cnn_model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m \u001b[43mcnn_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m     32\u001b[0m cnn_loss, cnn_accuracy \u001b[38;5;241m=\u001b[39m cnn_model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test_dl)\n",
      "File \u001b[1;32mc:\\Users\\Hansel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Hansel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\models\\functional.py:273\u001b[0m, in \u001b[0;36mFunctional._adjust_input_rank\u001b[1;34m(self, flat_inputs)\u001b[0m\n\u001b[0;32m    271\u001b[0m             adjusted\u001b[38;5;241m.\u001b[39mappend(ops\u001b[38;5;241m.\u001b[39mexpand_dims(x, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    272\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m--> 273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    274\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid input shape for input \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Expected shape \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    275\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mref_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but input has incompatible shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    276\u001b[0m     )\n\u001b[0;32m    277\u001b[0m \u001b[38;5;66;03m# Add back metadata.\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(flat_inputs)):\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInvalid input shape for input Tensor(\"data:0\", shape=(None, 9), dtype=float32). Expected shape (None, 128, 128, 3), but input has incompatible shape (None, 9)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 9), dtype=float32)\n  • training=True\n  • mask=None"
     ]
    }
   ],
   "source": [
    "# Step 3: Deep Learning Approach with CNN\n",
    "\n",
    "# Step 6: Deep Learning Approach with CNN\n",
    "# Split data for deep learning (use segmented images directly)\n",
    "X_train_dl, X_test_dl, y_train_dl, y_test_dl = train_test_split(X_segmented, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# One-hot encode labels for deep learning model\n",
    "y_train_dl = to_categorical(y_train_dl, num_classes=3)\n",
    "y_test_dl = to_categorical(y_test_dl, num_classes=3)\n",
    "\n",
    "# Define CNN model\n",
    "cnn_model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "cnn_model.fit(X_train, y_train_dl, epochs=10, validation_split=0.2, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "cnn_loss, cnn_accuracy = cnn_model.evaluate(X_test, y_test_dl)\n",
    "print(\"CNN Accuracy:\", cnn_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
